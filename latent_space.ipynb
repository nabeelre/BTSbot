{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e122c593",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.pyplot as plt\n",
    "import umap.umap_ as umap\n",
    "# import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import architectures_torch as architectures\n",
    "from torch_utils import FlexibleDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "from os import path\n",
    "import torch\n",
    "import json\n",
    "import tqdm\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"serif\",\n",
    "    \"animation.embed_limit\": 100\n",
    "})\n",
    "\n",
    "# tf.keras.backend.clear_session()\n",
    "# tf.config.set_visible_devices([], 'GPU')\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "metadata_cols = [\n",
    "    \"sgscore1\", \"distpsnr1\", \"sgscore2\", \"distpsnr2\",\n",
    "    \"fwhm\", \"magpsf\", \"sigmapsf\", \"chipsf\", \"ra\",\n",
    "    \"dec\", \"diffmaglim\", \"ndethist\", \"nmtchps\", \"age\",\n",
    "    \"days_since_peak\", \"days_to_peak\", \"peakmag_so_far\",\n",
    "    \"new_drb\", \"ncovhist\", \"nnotdet\", \"chinr\", \"sharpnr\",\n",
    "    \"scorr\", \"sky\", \"maxmag_so_far\"\n",
    "]\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3190b908",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_torch_embedding(model_dir,\n",
    "                        cand_path, trips_path=None,\n",
    "                        metadata_cols=None, validate_model=True,\n",
    "                        umap_seed=2):\n",
    "    # Check for multiple GPUs\n",
    "    multi_gpu = False\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(f\"Using {torch.cuda.device_count()} GPUs!\")\n",
    "        multi_gpu = True\n",
    "    \n",
    "    need_triplets = trips_path is not None\n",
    "    need_metadata = metadata_cols is not None\n",
    "\n",
    "    cand = pd.read_csv(cand_path, index_col=None)\n",
    "    labels_tensor = torch.tensor(cand['label'].values, dtype=torch.long)\n",
    "\n",
    "    triplets_tensor = None\n",
    "    if need_triplets:\n",
    "        triplets_np = np.load(trips_path).astype(np.float32)\n",
    "        triplets_np = np.transpose(triplets_np, (0, 3, 1, 2))\n",
    "        triplets_tensor = torch.from_numpy(triplets_np.copy())\n",
    "\n",
    "    metadata_tensor = None\n",
    "    if need_metadata:\n",
    "        metadata_values = cand[metadata_cols].values.astype(np.float32)\n",
    "        metadata_tensor = torch.tensor(metadata_values)\n",
    "\n",
    "    if multi_gpu:\n",
    "        batch_size = 1024 // torch.cuda.device_count()\n",
    "    else:\n",
    "        batch_size = 1024\n",
    "    \n",
    "    dataloader = DataLoader(\n",
    "        dataset=FlexibleDataset(\n",
    "            images=triplets_tensor,\n",
    "            metadata=metadata_tensor,\n",
    "            labels=labels_tensor,\n",
    "        ), batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True\n",
    "    )\n",
    "    \n",
    "    with open(model_dir+\"report.json\") as report:\n",
    "        config = json.load(report)['train_config']\n",
    "\n",
    "    try:\n",
    "        if config['model_name'] == \"SwinV2_t\":\n",
    "            config['model_name'] = \"SwinV2\"\n",
    "        model_type = getattr(architectures, config['model_name'])\n",
    "    except AttributeError:\n",
    "        print(f\"Could not find model of name {config['model_name']}\")\n",
    "        exit(0)\n",
    "    model = model_type(config).to(device)\n",
    "    model.load_state_dict(\n",
    "        torch.load(\n",
    "            path.join(model_dir, \"best_model.pth\"),\n",
    "            map_location=torch.device('cpu')\n",
    "        )\n",
    "    )\n",
    "    model = model.to(device).eval()\n",
    "    \n",
    "    if multi_gpu:\n",
    "        model = torch.nn.DataParallel(model)\n",
    "    \n",
    "    all_embs = []\n",
    "    all_raw_preds = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        if need_triplets and need_metadata:\n",
    "            if validate_model:\n",
    "                for batch in tqdm.tqdm(dataloader):\n",
    "                    images_batch, meta_batch, _ = batch\n",
    "                    images_batch = images_batch.to(device, non_blocking=True)\n",
    "                    meta_batch = meta_batch.to(device, non_blocking=True)\n",
    "                    raw_preds = torch.sigmoid(\n",
    "                        model(images_batch, meta_batch).cpu()\n",
    "                    )\n",
    "                    all_raw_preds.append(raw_preds)\n",
    "            \n",
    "            if multi_gpu:\n",
    "                # If using multiple GPUs, model is wrapped in DataParallel\n",
    "                # access the model with .module\n",
    "                emb_model = model.module\n",
    "            else:\n",
    "                emb_model = model\n",
    "            if config['model_name'] == \"mm_SwinV2\":\n",
    "                pass\n",
    "                # emb_model.combined_head = nn.Sequential(\n",
    "                #     nn.Linear(\n",
    "                #         emb_model.combined_head[0].in_features,\n",
    "                #         emb_model.combined_head[0].out_features\n",
    "                #     ),\n",
    "                #     nn.ReLU()\n",
    "                # )\n",
    "            elif config['model_name'] == \"mm_MaxViT\":\n",
    "                emb_model.combined_head = emb_model.combined_head[:4]\n",
    "            emb_model = emb_model.to(device).eval()\n",
    "            if multi_gpu:\n",
    "                emb_model = torch.nn.DataParallel(emb_model)\n",
    "\n",
    "            for batch in tqdm.tqdm(dataloader):\n",
    "                images_batch, meta_batch, _ = batch\n",
    "                images_batch = images_batch.to(device, non_blocking=True)\n",
    "                meta_batch = meta_batch.to(device, non_blocking=True)\n",
    "                embs = emb_model(\n",
    "                    images_batch, meta_batch\n",
    "                )\n",
    "                \n",
    "                all_embs.append(embs.cpu())\n",
    "        elif need_triplets:\n",
    "            if validate_model:\n",
    "                for batch in tqdm.tqdm(dataloader):\n",
    "                    images_batch, _ = batch\n",
    "                    images_batch = images_batch.to(device, non_blocking=True)\n",
    "                    raw_preds = torch.sigmoid(\n",
    "                        model(images_batch).cpu()\n",
    "                    )\n",
    "                    all_raw_preds.append(raw_preds)\n",
    "            \n",
    "            if multi_gpu:\n",
    "                emb_model = model.module\n",
    "            else:\n",
    "                emb_model = model\n",
    "            if config['model_name'] == \"SwinV2\":\n",
    "                pass\n",
    "                # emb_model.swin.head = nn.Sequential(\n",
    "                #     nn.Linear(\n",
    "                #         emb_model.swin.head[0].in_features,\n",
    "                #         emb_model.swin.head[0].out_features\n",
    "                #     ),\n",
    "                #     nn.Linear(\n",
    "                #         emb_model.swin.head[1].in_features,\n",
    "                #         emb_model.swin.head[1].out_features\n",
    "                #     ),\n",
    "                #     nn.ReLU()\n",
    "                # )\n",
    "            elif config['model_name'] == \"MaxViT\":\n",
    "                emb_model.maxvit.head = emb_model.maxvit.head[:5]\n",
    "            elif config['model_name'] == \"ConvNeXt\":\n",
    "                emb_model.convnext.head = emb_model.convnext.head[:7]\n",
    "\n",
    "            emb_model = emb_model.to(device).eval()\n",
    "            if multi_gpu:\n",
    "                emb_model = torch.nn.DataParallel(emb_model)\n",
    "\n",
    "            for batch in tqdm.tqdm(dataloader):\n",
    "                images_batch, _ = batch\n",
    "                images_batch = images_batch.to(device, non_blocking=True)\n",
    "                embs = emb_model(images_batch)\n",
    "                \n",
    "                all_embs.append(embs.cpu())\n",
    "        elif need_metadata:\n",
    "            pass\n",
    "\n",
    "    if validate_model:\n",
    "        raw_preds_np = torch.cat(all_raw_preds, dim=0).squeeze().numpy()\n",
    "        labels_np = labels_tensor.cpu().numpy()\n",
    "        accuracy = (raw_preds_np.round() == labels_np).sum() / len(labels_np)\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "        cand['raw_preds'] = raw_preds_np\n",
    "        \n",
    "    embs = torch.cat(all_embs, dim=0).squeeze().numpy()\n",
    "    print(np.shape(embs))\n",
    "    \n",
    "    umap_model = umap.UMAP(random_state=umap_seed)\n",
    "    umap_emb = umap_model.fit_transform(embs)\n",
    "\n",
    "    cand[\"umap_emb_1\"] = umap_emb[:, 0]\n",
    "    cand[\"umap_emb_2\"] = umap_emb[:, 1]\n",
    "\n",
    "    return cand\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec6876b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mm_swinv2_cand = get_torch_embedding(\n",
    "#     model_dir=\"models/mm_SwinV2_v11_N100_cuda/playful-star-48/\",\n",
    "#     cand_path=\"data/val_cand_v11_N100.csv\",\n",
    "#     trips_path=\"data/val_triplets_v11_N100.npy\",\n",
    "#     metadata_cols=metadata_cols,\n",
    "#     validate_model=True\n",
    "# )\n",
    "# mm_swinv2_cand.to_csv(\"embedding_cands/mm_swinv2_playful_star_48_v11_N100.csv\", index=False)\n",
    "\n",
    "# swinv2_cand = get_torch_embedding(\n",
    "#     model_dir=\"models/SwinV2_t_v11_N100_cuda/magic-plant-37/\",\n",
    "#     cand_path=\"data/val_cand_v11_N100.csv\",\n",
    "#     trips_path=\"data/val_triplets_v11_N100.npy\",\n",
    "#     validate_model=True\n",
    "# )\n",
    "# swinv2_cand.to_csv(\"embedding_cands/swinv2_magic_plant_37_v11_N100.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf983686",
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_maxvit_cand = get_torch_embedding(\n",
    "    model_dir=\"models/mm_MaxViT_v11_N100_cuda/hardy-yogurt-123/\",\n",
    "    cand_path=\"data/test_cand_v11_N100.csv\",\n",
    "    trips_path=\"data/test_triplets_v11_N100.npy\",\n",
    "    metadata_cols=metadata_cols,\n",
    "    validate_model=True\n",
    ")\n",
    "mm_maxvit_cand.to_csv(\"embedding_cands/mm_maxvit_hardy_yogurt_123_v11_test.csv\", index=False)\n",
    "\n",
    "maxvit_cand = get_torch_embedding(\n",
    "    model_dir=\"models/MaxViT_v11_N100_cuda/atomic-sweep-3/\",\n",
    "    cand_path=\"data/test_cand_v11_N100.csv\",\n",
    "    trips_path=\"data/test_triplets_v11_N100.npy\",\n",
    "    validate_model=True\n",
    ")\n",
    "maxvit_cand.to_csv(\"embedding_cands/maxvit_atomic_sweep_3_v11_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba06093",
   "metadata": {},
   "outputs": [],
   "source": [
    "convnext_cand = get_torch_embedding(\n",
    "    model_dir=\"models/ConvNeXt_v10_N100_cuda/fluent-sweep-14/\",\n",
    "    cand_path=\"data/val_cand_v10_N100.csv\",\n",
    "    trips_path=\"data/val_triplets_v10_N100.npy\",\n",
    "    validate_model=True\n",
    ")\n",
    "convnext_cand.to_csv(\"embedding_cands/convnext_fluent_sweep_14_v10_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "57ebb3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mm_swin_cand = pd.read_csv(\"embedding_cands/mm_swin_cand_playful_star_48_v11_N100.csv\", index_col=None)\n",
    "# swinv2_cand = pd.read_csv(\"embedding_cands/swinv2_magic_plant_37_v11_N100.csv\", index_col=None)\n",
    "\n",
    "mm_maxvit_cand = pd.read_csv(\"embedding_cands/mm_maxvit_hardy_yogurt_123_v11_test.csv\", index_col=None)\n",
    "maxvit_cand = pd.read_csv(\"embedding_cands/maxvit_atomic_sweep_3_v11_test.csv\", index_col=None)\n",
    "\n",
    "convnext_cand = pd.read_csv(\"embedding_cands/convnext_fluent_sweep_14_v10_test.csv\", index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43235eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tf_embedding(model_path,\n",
    "                  cand_path, trips_path=None,\n",
    "                  layer_idx=-3, metadata_cols=None,\n",
    "                  validate_model=False, umap_seed=2):\n",
    "    need_triplets = trips_path is not None\n",
    "    need_metadata = metadata_cols is not None\n",
    "    \n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    emb_model = tf.keras.Model(\n",
    "        inputs=model.input,\n",
    "        outputs=model.get_layer(model.layers[layer_idx].name).output\n",
    "    )\n",
    "    \n",
    "    cand = pd.read_csv(cand_path, index_col=None)\n",
    "    if need_triplets:\n",
    "        triplets = np.load(trips_path, mmap_mode='r')\n",
    "\n",
    "    if need_triplets and need_metadata:\n",
    "        embeddings = emb_model.predict(\n",
    "            [triplets, cand.loc[:, metadata_cols]],\n",
    "            batch_size=512, verbose=1\n",
    "        )\n",
    "        \n",
    "        if validate_model:\n",
    "            raw_preds = model.predict(\n",
    "                [triplets, cand.loc[:, metadata_cols]],\n",
    "                batch_size=512, verbose=1\n",
    "            )\n",
    "    elif need_triplets:\n",
    "        embeddings = emb_model.predict(\n",
    "            triplets, batch_size=512, verbose=1\n",
    "        )\n",
    "        \n",
    "        if validate_model:\n",
    "            raw_preds = model.predict(\n",
    "                triplets, batch_size=512, verbose=1\n",
    "            )\n",
    "    elif need_metadata:\n",
    "        embeddings = emb_model.predict(\n",
    "            cand.loc[:, metadata_cols],\n",
    "            batch_size=512, verbose=1\n",
    "        )\n",
    "        \n",
    "        if validate_model:\n",
    "            raw_preds = model.predict(\n",
    "                cand.loc[:, metadata_cols],\n",
    "                batch_size=512, verbose=1\n",
    "            )   \n",
    "    \n",
    "    if validate_model:\n",
    "        preds = np.rint(np.transpose(raw_preds))[0].astype(int)\n",
    "        results = preds == cand[\"label\"].to_numpy()\n",
    "        print(f\"Overall test accuracy {100*np.sum(results) / len(results):.2f}%\")\n",
    "\n",
    "    umap_model = umap.UMAP(random_state=umap_seed)\n",
    "    umap_emb = umap_model.fit_transform(embeddings)\n",
    "\n",
    "    if validate_model:\n",
    "        cand['raw_preds'] = raw_preds\n",
    "    cand[\"umap_emb_1\"] = umap_emb[:, 0]\n",
    "    cand[\"umap_emb_2\"] = umap_emb[:, 1]\n",
    "\n",
    "    return cand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477c3780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mm_cnn_cand = get_tf_embedding(\n",
    "#     model_path=\"production_models/best_model\",\n",
    "#     cand_path=\"data/v10/test_cand_v10_N100.csv\",\n",
    "#     trips_path=\"data/v10/test_triplets_v10_N100.npy\",\n",
    "#     metadata_cols=metadata_cols,\n",
    "#     validate_model=True\n",
    "# )\n",
    "# mm_cnn_cand.to_csv(\"embedding_cands/mm_cnn_prod_v10_N100.csv\", index=False)\n",
    "\n",
    "# cnn_cand = get_tf_embedding(\n",
    "#     model_path=\"models/um_cnn_v10_N100/effortless-butterfly-905/best_model/\",\n",
    "#     cand_path=\"data/v10/test_cand_v10_N100.csv\",\n",
    "#     trips_path=\"data/v10/test_triplets_v10_N100.npy\",\n",
    "#     validate_model=True\n",
    "# )\n",
    "# cnn_cand.to_csv(\"embedding_cands/cnn_effortless_butterfly_905_v10_N100.csv\", index=False)\n",
    "\n",
    "# mdata_cand = get_tf_embedding(\n",
    "#     model_path=\"models/um_nn_v10_N30/swept-deluge-897/best_model/\",\n",
    "#     cand_path=\"data/v10/test_cand_v10_N30.csv\",\n",
    "#     metadata_cols=metadata_cols,\n",
    "#     validate_model=True\n",
    "# )\n",
    "# mdata_cand.to_csv(\"embedding_cands/mdata_swept_deluge_897_v10_N30.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d581be92",
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_cand = pd.read_csv(\"embedding_cands/mm_cnn_prod_v10_N100.csv\", index_col=None)\n",
    "cnn_cand = pd.read_csv(\"embedding_cands/cnn_effortless_butterfly_905_v10_N100.csv\", index_col=None)\n",
    "mdata_cand = pd.read_csv(\"embedding_cands/mdata_swept_deluge_897_v10_N30.csv\", index_col=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "002e1beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_umap_embedding(\n",
    "    cand, color_col=None, colormap='viridis', s=5, alpha=1.0,\n",
    "    figsize=(10, 8), title=None, colorbar_label=False, ax=None\n",
    "):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.figure(figsize=figsize), plt.gca()\n",
    "    \n",
    "    embedding = cand[['umap_emb_1', 'umap_emb_2']].to_numpy()\n",
    "    \n",
    "    # If labels are provided, use them for coloring\n",
    "    if color_col is not None:\n",
    "        if color_col == \"source_set\":\n",
    "            source_set_unique = cand[\"source_set\"].unique()\n",
    "            source_set_map = {label: i for i, label in enumerate(source_set_unique)}\n",
    "            color_col_values = cand[\"source_set\"].map(source_set_map)\n",
    "        else:\n",
    "            color_col_values = cand[color_col]\n",
    "        \n",
    "        scatter = ax.scatter(embedding[:, 0], embedding[:, 1],\n",
    "                             c=color_col_values, cmap=colormap, s=s, alpha=alpha)\n",
    "        if colorbar_label:\n",
    "            cbar = plt.colorbar(scatter, ax=ax)\n",
    "            if isinstance(colorbar_label, bool):\n",
    "                colorbar_label_str = color_col\n",
    "            else:\n",
    "                colorbar_label_str = colorbar_label\n",
    "            cbar.set_label(colorbar_label_str)\n",
    "            \n",
    "            if color_col == \"source_set\" and ax.collections:\n",
    "                scatter_plot = ax.collections[0]\n",
    "                # Check if the scatter plot has an associated colorbar\n",
    "                if hasattr(scatter_plot, 'colorbar') and scatter_plot.colorbar is not None:\n",
    "                    cb = scatter_plot.colorbar\n",
    "                    \n",
    "                    # Set the ticks to be the integer values 0, 1, ..., n_unique_labels-1\n",
    "                    ticks = np.arange(len(source_set_unique))\n",
    "                    cb.set_ticks(ticks)\n",
    "                    \n",
    "                    # Set the tick labels to be the original string values\n",
    "                    cb.set_ticklabels(source_set_unique)\n",
    "    else:\n",
    "        ax.scatter(embedding[:, 0], embedding[:, 1], s=s, alpha=alpha)\n",
    "    \n",
    "    ax.set_xlabel('UMAP_1')\n",
    "    ax.set_ylabel('UMAP_2')\n",
    "    \n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd121577",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18, 5))\n",
    "gs = fig.add_gridspec(1, 3)\n",
    "ax1 = fig.add_subplot(gs[0])\n",
    "ax2 = fig.add_subplot(gs[1])\n",
    "ax3 = fig.add_subplot(gs[2])\n",
    "\n",
    "color_col = \"source_set\"\n",
    "\n",
    "ax1.set_title(\"Metadata Embedding\")\n",
    "ax1 = plot_umap_embedding(\n",
    "    mdata_cand, color_col=color_col, \n",
    "    alpha=0.5, s=4, colormap='viridis', ax=ax1\n",
    ")\n",
    "\n",
    "ax2.set_title(\"Images Embedding\")\n",
    "ax2 = plot_umap_embedding(\n",
    "    cnn_cand, color_col=color_col,\n",
    "    alpha=0.5, s=4, colormap='viridis', ax=ax2\n",
    ")\n",
    "\n",
    "ax3.set_title(\"Multi-modal Embedding\")\n",
    "ax3 = plot_umap_embedding(\n",
    "    mm_cand, color_col=color_col,\n",
    "    alpha=0.5, s=4, colormap='viridis', \n",
    "    colorbar_label=True, ax=ax3\n",
    ")\n",
    "\n",
    "# plt.savefig(\"BTSbot_latent_spaces.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53861d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 10))\n",
    "gs = fig.add_gridspec(2, 2)\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "ax3 = fig.add_subplot(gs[1, 0])\n",
    "ax4 = fig.add_subplot(gs[1, 1])\n",
    "\n",
    "color_col = \"source_set\"\n",
    "\n",
    "ax1.set_title(\"Metadata Embedding\")\n",
    "ax1 = plot_umap_embedding(\n",
    "    cnn_cand, color_col=color_col, \n",
    "    alpha=0.5, s=4, colormap='viridis', ax=ax1\n",
    ")\n",
    "\n",
    "ax2.set_title(\"Images Embedding\")\n",
    "ax2 = plot_umap_embedding(\n",
    "    mm_cand, color_col=color_col,\n",
    "    alpha=0.5, s=4, colormap='viridis', ax=ax2\n",
    ")\n",
    "\n",
    "ax3.set_title(\"Multi-modal Embedding\")\n",
    "ax3 = plot_umap_embedding(\n",
    "    maxvit_cand, color_col=color_col,\n",
    "    alpha=0.5, s=4, colormap='viridis', ax=ax3\n",
    ")\n",
    "\n",
    "ax4.set_title(\"SwinV2 Embedding\")\n",
    "ax4 = plot_umap_embedding(\n",
    "    mm_maxvit_cand, color_col=color_col,\n",
    "    alpha=0.5, s=4, colormap='viridis', ax=ax4\n",
    ")\n",
    "\n",
    "# plt.savefig(\"BTSbot_latent_spaces.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580e309f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930943e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b77dcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def animate_embedding_evolution(cand, objectId=None):\n",
    "    if objectId is None:\n",
    "        # Select one random objectId\n",
    "        unique_object_ids = cand.loc[cand['label'] == 1]['objectId'].unique()\n",
    "        objectId = np.random.choice(unique_object_ids)\n",
    "        print(f\"Selected objectId: {objectId}\")\n",
    "\n",
    "    # Filter data for the selected objectId and sort by jd\n",
    "    object_data = cand[cand['objectId'] == objectId].copy()\n",
    "    object_data.sort_values('jd', inplace=True)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    plt.tight_layout()\n",
    "\n",
    "    emb1 = cand['umap_emb_1']\n",
    "    emb2 = cand['umap_emb_2']\n",
    "\n",
    "    obj_emb1 = object_data['umap_emb_1']\n",
    "    obj_emb2 = object_data['umap_emb_2']\n",
    "\n",
    "    # --- Background scatter plot ---\n",
    "    # Create a mapping from unique source_set strings to integers for coloring\n",
    "    unique_source_sets = cand['source_set'].unique()\n",
    "    source_set_map = {source: i for i, source in enumerate(unique_source_sets)}\n",
    "    colors_for_background = cand['source_set'].map(source_set_map)\n",
    "\n",
    "    cmap_bg = 'viridis'\n",
    "    background_scatter = ax.scatter(\n",
    "        emb1, emb2, c=colors_for_background,\n",
    "        cmap=cmap_bg, s=10, alpha=0.3,\n",
    "        label='All other objects'\n",
    "    )\n",
    "    # --- End of background scatter plot ---\n",
    "\n",
    "    # Set plot limits based on the overall embedding range\n",
    "    ax.set_xlim(emb1.min() - 1, emb1.max() + 1)\n",
    "    ax.set_ylim(emb2.min() - 1, emb2.max() + 1)\n",
    "    ax.set_title(f'Movement of object {objectId} in embedding space')\n",
    "\n",
    "    # Animated point (foreground)\n",
    "    animated_point_scatter = ax.scatter([], [], s=450, c='gold', marker='*', zorder=5,\n",
    "                                        edgecolors='black', label=f'Object {objectId}') # Emphasize animated point\n",
    "    trail, = ax.plot([], [], 'o-', alpha=0.7, linewidth=4, zorder=4) # Line for the trail\n",
    "    current_text = ax.text(0.02, 0.9, '', transform=ax.transAxes, fontsize=12)\n",
    "\n",
    "    # Add a legend for background points if cmap is 'tab10' or similar categorical\n",
    "    if cmap_bg.startswith('tab'): # Heuristic for categorical colormaps\n",
    "        handles, labels = background_scatter.legend_elements(prop=\"colors\", alpha=0.6)\n",
    "        # Create proxy artists for the legend if needed, or directly use handles if they are appropriate\n",
    "        legend_handles = [plt.Line2D([0], [0], marker='o', color='w', label=unique_source_sets[i],\n",
    "                          markersize=10) for i, handle in enumerate(handles)]\n",
    "        ax.legend(handles=legend_handles, title=\"Source Sets (Background)\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "    def init():\n",
    "        animated_point_scatter.set_offsets(np.empty((0, 2)))\n",
    "        trail.set_data([], [])\n",
    "        current_text.set_text('')\n",
    "        return animated_point_scatter, trail, current_text\n",
    "\n",
    "    def animate(i):\n",
    "        animated_point_scatter.set_offsets(np.c_[obj_emb1.iloc[i], obj_emb2.iloc[i]])\n",
    "        trail.set_data(obj_emb1.iloc[:i+1], obj_emb2.iloc[:i+1])\n",
    "        current_text.set_text(\n",
    "            f'Source Set: {object_data[\"source_set\"].iloc[i]}\\n'\n",
    "            f'JD: {object_data[\"jd\"].iloc[i]:.2f}\\n'\n",
    "            f'Magnitude: {object_data[\"magpsf\"].iloc[i]:.2f}\\n'\n",
    "            f'Age: {object_data[\"age\"].iloc[i]:.5f}'\n",
    "        )\n",
    "        return animated_point_scatter, trail, current_text\n",
    "\n",
    "    if not object_data.empty:\n",
    "        anim = animation.FuncAnimation(fig, animate, init_func=init, frames=len(object_data), interval=200, blit=True)\n",
    "        display(HTML(anim.to_jshtml()))\n",
    "    else:\n",
    "        print(f\"No data found for objectId: {objectId}\")\n",
    "    \n",
    "    plt.close(fig) # Keep this commented out for now to see the final static plot with legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfdd3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "animate_embedding_evolution(swinv2_cand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420e3804",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BTSbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
